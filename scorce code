# Step 1: Import necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
# Step 3: Exploratory Data Analysis (EDA)

# Check the first few rows of the dataset
print(df.head())
# Check for missing values
print(df.isnull().sum())
# Basic statistics
print(df.describe())
# Visualize the distribution of 'Age' and 'MonthlySpend'
sns.histplot(df['Age'], kde=True, color='blue')
plt.title('Age Distribution')
plt.show()
sns.histplot(df['MonthlySpend'], kde=True, color='green')
plt.title('Monthly Spend Distribution')
plt.show()
# Select only numeric columns for correlation calculation
numeric_df = df.select_dtypes(include=[np.number])

# Heatmap to visualize correlation
plt.figure(figsize=(10, 6))
sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap')
plt.show()
# Visualizing churn distribution
sns.countplot(x='Churn', data=df)
plt.title('Churn Distribution')
plt.show()
# Step 4: Data Preprocessing

# Encode categorical features (Gender and SubscriptionType)
label_encoder = LabelEncoder()
df['Gender'] = label_encoder.fit_transform(df['Gender'])
df['SubscriptionType'] = label_encoder.fit_transform(df['SubscriptionType'])
print(df)
# Step 5: Feature Engineering and Splitting the Data

# Define features (X) and target variable (y)
X = df.drop(columns=['CustomerID', 'Churn'])
y = df['Churn']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Print the shapes of the splits to verify the sizes
print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)
# Step 6: Model Selection and Training

# Initialize RandomForestClassifier (you can try other models too)
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
model.fit(X_train, y_train)
# Step 7: Model Evaluation

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model performance
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
# Step 8: Visualization of the Confusion Matrix
plt.figure(figsize=(8,6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues',
            xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
# New customer data for prediction
new_customer = pd.DataFrame({
    'Age': [30],
    'Gender': [0],          # 0 represents 'Male' if that was the encoding during training
    'Tenure': [3],
    'MonthlySpend': [150],
    'SubscriptionType': [0] # 0 represents 'Basic' if that was the encoding during training
})

# Predict churn
prediction = model.predict(new_customer)
print("New Customer Churn Prediction:", "Churned" if prediction[0] == 1 else "Not Churned")
feature_importances = pd.Series(model.feature_importances_, index=X.columns)
feature_importances.nlargest(5).plot(kind='barh')
plt.show()
import joblib
joblib.dump(model, 'churn_model.pkl')
import joblib
joblib.dump(model, 'churn_model.pkl')
print("âœ… Model saved as churn_model.pkl")

